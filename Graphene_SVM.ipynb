{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Graphene SVM Testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "from sklearn.svm import OneClassSVM\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Read in the data from the numpy array files provided\n",
    "pp = np.load('./perfect_patches.npy')\n",
    "dp = np.load('./defect_patches.npy')\n",
    "\n",
    "# Label the data as 1 for within boundary and -1 for outlier points as output by OneClassSVM\n",
    "pp_labels = np.ones(len(pp))\n",
    "dp_labels = np.ones(len(dp)) * -1\n",
    "\n",
    "patches = np.concatenate([pp, dp])\n",
    "gt = np.concatenate([pp_labels, dp_labels])\n",
    "\n",
    "xy = list(zip(patches, gt))     # put labels with data in (data, label) tuple\n",
    "random.shuffle(xy)              # shuffle the tuples\n",
    "patches, gt = list(zip(*xy))    # unzip the tuples to get patches and ground truths as vectors\n",
    "patches = np.array(patches)\n",
    "\n",
    "# Reshape data for compatibility with sklearn as a 2d array (as opposed to 3d)\n",
    "#nsamples_tr, nx_tr, ny_tr = pp.shape\n",
    "#d2_train = pp.reshape((nsamples_tr, nx_tr*ny_tr))\n",
    "#nsamples_test, nx_test, ny_test = dp.shape\n",
    "#d2_test = dp.reshape((nsamples_test, nx_test*ny_test))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Define Model for OneClassSVM, train and test with the reshaped data for perfect patches and defect patches:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Error rbf: 1.38 %\n"
     ]
    }
   ],
   "source": [
    "model = OneClassSVM(gamma='scale',\n",
    "                    nu=0.005, kernel='rbf')\n",
    "model1 = OneClassSVM(gamma='scale',\n",
    "                    nu=0.005, kernel='poly')\n",
    "model2 = OneClassSVM(gamma='scale',\n",
    "                    nu=0.005, kernel='sigmoid')\n",
    "model3 = OneClassSVM(gamma='scale',\n",
    "                    nu=0.005, kernel='linear')\n",
    "\n",
    "n_samples, nx, ny = patches.shape\n",
    "d2 = patches.reshape((n_samples, nx*ny))\n",
    "\n",
    "model.fit(d2)\n",
    "label_predict = model.predict(d2)\n",
    "\n",
    "model1.fit(d2)\n",
    "label_predict1 = model1.predict(d2)\n",
    "\n",
    "model2.fit(d2)\n",
    "label_predict2 = model2.predict(d2)\n",
    "\n",
    "model3.fit(d2)\n",
    "label_predict3 = model3.predict(d2)\n",
    "\n",
    "error_percent = (sum(gt - label_predict) / len(gt)) * 100\n",
    "print(f'Training Error rbf: {error_percent:.2f} %')\n",
    "\n",
    "\n",
    "#model.fit(d2_train)\n",
    "#label_train = model.predict(d2_train)\n",
    "#label_test = model.predict(d2_test)\n",
    "\n",
    "#n_error_train = (label_train[label_train == -1].size / label_train.size) * 100\n",
    "#n_error_test = (label_test[label_test == 1].size / label_test.size) * 100\n",
    "\n",
    "#print(f'Training Error: {n_error_train} %')\n",
    "#print(f'Testing Error: {n_error_test} %')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Training Error is the percentage of the training data which is assigned a label which does not match the ground truth.\n",
    "\n",
    "Use the full_stack data for testing the trained model."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "cannot resize this array: it does not own its data",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Input \u001B[0;32mIn [324]\u001B[0m, in \u001B[0;36m<cell line: 4>\u001B[0;34m()\u001B[0m\n\u001B[1;32m     13\u001B[0m smaller_samples, nx, ny \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39mshape(smaller_patches)\n\u001B[1;32m     14\u001B[0m smaller_2d \u001B[38;5;241m=\u001B[39m smaller_patches\u001B[38;5;241m.\u001B[39mreshape((smaller_samples, nx\u001B[38;5;241m*\u001B[39mny))\n\u001B[0;32m---> 15\u001B[0m \u001B[43msmaller_2d\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mresize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m4\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m2304\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m     16\u001B[0m smaller_predicted_labels \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(smaller_2d)            \u001B[38;5;66;03m# Breaks here since N features are incorrect\u001B[39;00m\n\u001B[1;32m     17\u001B[0m \u001B[38;5;28mprint\u001B[39m(smaller_predicted_labels)\n",
      "\u001B[0;31mValueError\u001B[0m: cannot resize this array: it does not own its data"
     ]
    }
   ],
   "source": [
    "graphene = np.load('./full-stack.npy')\n",
    "full_stack_labels = []\n",
    "\n",
    "for i in range(len(graphene)):\n",
    "    smaller_patches = 0\n",
    "    sample = np.squeeze(graphene[i])\n",
    "    sample_patches = np.split(sample, 4, axis=0)\n",
    "\n",
    "    for j in sample_patches:\n",
    "        smaller_patches = np.split(j, 4, axis=1)\n",
    "        smaller_patches = np.array(smaller_patches)\n",
    "\n",
    "    smaller_samples, nx, ny = np.shape(smaller_patches)\n",
    "    smaller_2d = smaller_patches.reshape((smaller_samples, nx*ny))\n",
    "    smaller_2d.resize(4, 2304)\n",
    "    smaller_predicted_labels = model.predict(smaller_2d)            # Breaks here since N features are incorrect\n",
    "    print(smaller_predicted_labels)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}